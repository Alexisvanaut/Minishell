To do list PARSING (alvanaut)

TO-DO Liste Parsing Minishell
🎯 Architecture générale
Structure de données principales

 Définir t_token (type, value, next)
 Définir t_command (args, redirections, next pour pipes)
 Définir t_redirect (type, filename, delimiter pour heredoc)
 Créer les énumérations pour les types de tokens

Headers et includes

 Créer minishell.h avec toutes les structures
 Inclure les bonnes librairies (readline, stdio, stdlib, etc.)
 Définir les macros d'erreur

📝 Étape 1: Lexer/Tokenizer
Lecture de l'input

 Implémenter la boucle principale avec readline()
 Gérer le prompt "minishell$ "
 Ajouter à l'historique avec add_history()

Tokenisation de base

 Fonction tokenize() qui découpe la ligne
 Identifier les métacaractères : |, <, >, >>, <<
 Séparer les mots (arguments/commandes)
 Gérer les espaces comme délimiteurs

Gestion des quotes

 Détecter les quotes simples '
 Détecter les quotes doubles "
 Vérifier que les quotes sont fermées
 Dans les quotes simples : tout est littéral (pas d'expansion)
 Dans les quotes doubles : expansion des $ mais pas des autres métacaractères

🧠 Étape 2: Parsing syntaxique
Validation syntaxique

 Vérifier qu'on ne commence/finit pas par un pipe |
 Vérifier qu'il n'y a pas deux pipes consécutifs ||
 Vérifier que les redirections ont un fichier après (<, >, >>)
 Vérifier que heredoc << a un délimiteur

Construction de l'AST (liste de commandes)

 Parser les pipes pour séparer les commandes
 Pour chaque commande, extraire :

 Le nom de la commande (premier argument)
 Les arguments
 Les redirections d'entrée (<, <<)
 Les redirections de sortie (>, >>)



Gestion des redirections

 Identifier les redirections dans chaque commande
 Les retirer des arguments de la commande
 Les stocker dans la structure appropriée
 Gérer les redirections multiples (dernière gagne)

🔧 Étape 3: Expansions
Variables d'environnement

 Détecter les $VARIABLE dans les tokens
 Récupérer la valeur avec getenv()
 Remplacer $VAR par sa valeur
 Ne pas expanser dans les quotes simples
 Expanser dans les quotes doubles

Variables spéciales

 Implémenter $? (code de retour de la dernière commande)
 Gérer $0, $1, etc. si nécessaire (pas demandé explicitement)
 Gérer $$ (PID) si nécessaire

Cas limites d'expansion

 $ suivi de rien ou d'un caractère invalide
 Variables inexistantes (expansion vers chaîne vide)
 Expansion dans différents contextes (commande, arguments, redirections)

🛡️ Étape 4: Gestion d'erreurs
Erreurs de syntaxe

 Messages d'erreur pour quotes non fermées
 Messages d'erreur pour redirections invalides
 Messages d'erreur pour pipes invalides
 Format des erreurs comme bash : bash: syntax error near unexpected token

Memory management

 Fonctions de libération pour t_token
 Fonctions de libération pour t_command
 Éviter les leaks dans tous les cas d'erreur
 Tester avec valgrind

🧪 Étape 5: Tests et debug
Tests unitaires

 Tester le tokenizer avec différents inputs
 Tester la gestion des quotes
 Tester les expansions de variables
 Tester les cas d'erreur

Tests d'intégration

 Comparer avec bash pour les cas complexes
 Tester les combinaisons : pipes + redirections + quotes + variables
 Tester les cas limites (ligne vide, que des espaces, etc.)

Debug

 Fonction d'affichage de la liste de tokens (debug)
 Fonction d'affichage de la structure de commandes (debug)
 Tests avec des inputs progressifs (simple → complexe)

📋 Ordre de développement recommandé

Structures de données et fonctions utilitaires de base
Tokenizer basique (sans quotes ni expansions)
Gestion des quotes simples et doubles
Parser syntaxique pour créer la structure de commandes
Expansions des variables d'environnement
Gestion d'erreurs et cas limites
Tests et optimisations

💡 Conseils

Commence simple : une commande sans arguments, puis ajoute la complexité
Utilise bash comme référence pour tous les comportements
Teste chaque fonction individuellement avant d'intégrer
N'oublie pas que readline() peut avoir des leaks (c'est autorisé)
Garde une variable globale pour les signaux uniquement